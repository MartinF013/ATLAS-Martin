import {
  s
} from "./chunk-ZLORWBMB.js";
import {
  o as o3
} from "./chunk-LJAT5UYW.js";
import {
  e as e4
} from "./chunk-YSWURJZW.js";
import {
  n as n2
} from "./chunk-DNPZNIDB.js";
import {
  e as e5
} from "./chunk-WW7VYUQW.js";
import {
  o
} from "./chunk-TEJEYVH4.js";
import {
  t
} from "./chunk-HEZ2ATGC.js";
import {
  e as e3
} from "./chunk-AALA53RH.js";
import {
  u
} from "./chunk-IJHFAZOW.js";
import {
  c
} from "./chunk-DMGVDNFD.js";
import {
  d
} from "./chunk-YAQGRU5B.js";
import {
  e as e2
} from "./chunk-46N7XS5M.js";
import {
  o as o2
} from "./chunk-A3QLZKCF.js";
import {
  a
} from "./chunk-OYAHQ564.js";
import {
  e
} from "./chunk-LGILR4HN.js";
import {
  i2 as i
} from "./chunk-I5UNY2WQ.js";
import {
  n
} from "./chunk-NAB3NF54.js";
import {
  O as O2
} from "./chunk-MDCKEJ7B.js";
import {
  O
} from "./chunk-VMF4NMEB.js";
import {
  r
} from "./chunk-CBQWMOBK.js";

// node_modules/@arcgis/core/views/3d/layers/support/markerUtils.js
var n3 = 64;
var o4 = n3 / 2;
var i2 = o4 / 5;
function e6(t2, n4) {
  return r(n4) ? m(t2, f(n4.style)) : null;
}
function m(r2, e7) {
  return r2.fromData(e7, () => o3(e7, n3, o4, i2));
}
function f(r2) {
  return "diamond" === r2 ? "kite" : r2;
}

// node_modules/@arcgis/core/chunks/LineMarker.glsl.js
function b(b2) {
  const x2 = new i(), P = b2.hasMultipassTerrain && (b2.output === o.Color || b2.output === o.Alpha);
  x2.include(s, b2), b2.output === o.Depth && x2.include(e4, b2);
  const { vertex: S, fragment: j } = x2;
  return j.include(a), d(x2, b2), x2.attributes.add(O.POSITION, "vec3"), x2.attributes.add(O.UV0, "vec2"), x2.attributes.add(O.AUXPOS1, "vec3"), x2.varyings.add("vColor", "vec4"), x2.varyings.add("vpos", "vec3"), x2.varyings.add("vUV", "vec2"), x2.varyings.add("vSize", "float"), x2.varyings.add("linearDepth", "float"), P && x2.varyings.add("depth", "float"), S.code.add(n`#define PERPENDICULAR(v) vec2(v.y, -v.x)
float interp(float ncp, vec4 a, vec4 b) {
return (-ncp - a.z) / (b.z - a.z);
}`), S.uniforms.add([new e("nearFar", (e7, r2) => r2.camera.nearFar), new e3("viewport", (e7, r2) => r2.camera.fullViewport)]), S.code.add(n`vec4 projectAndScale(vec4 pos) {
vec4 posNdc = proj * pos;
posNdc.xy *= viewport.zw / posNdc.w;
return posNdc;
}`), S.code.add(n`void clip(vec4 pos, inout vec4 prev) {
float vnp = nearFar[0] * 0.99;
if (prev.z > -nearFar[0]) {
prev = mix(pos, prev, interp(vnp, pos, prev));
}
}`), b2.draped || (S.uniforms.add(new e2("inverseProjectionMatrix", (e7, r2) => r2.camera.inverseProjectionMatrix)), S.code.add(n`vec3 inverseProject(vec4 posScreen) {
posScreen.xy = (posScreen.xy / viewport.zw) * posScreen.w;
return (inverseProjectionMatrix * posScreen).xyz;
}`), S.code.add(n`bool rayIntersectPlane(vec3 rayDir, vec3 planeOrigin, vec3 planeNormal, out vec3 intersection) {
float cos = dot(rayDir, planeNormal);
float t = dot(planeOrigin, planeNormal) / cos;
intersection = t * rayDir;
return abs(cos) > 0.001 && t > 0.0;
}`), S.uniforms.add(new o2("perScreenPixelRatio", (e7, r2) => r2.camera.perScreenPixelRatio)), S.code.add(n`
      vec4 toFront(vec4 displacedPosScreen, vec3 posLeft, vec3 posRight, vec3 prev, float lineWidth) {
        // Project displaced position back to camera space
        vec3 displacedPos = inverseProject(displacedPosScreen);

        // Calculate the plane that we want the marker to lie in. Note that this will always be an approximation since ribbon lines are generally
        // not planar and we do not know the actual position of the displaced prev vertices (they are offset in screen space, too).
        vec3 planeNormal = normalize(cross(posLeft - posRight, posLeft - prev));
        vec3 planeOrigin = posLeft;

        ${b2.hasCap ? "\n                if(prev.z > posLeft.z) {\n                  vec2 diff = posLeft.xy - posRight.xy;\n                  planeOrigin.xy += PERPENDICULAR(diff) / 2.0;\n                }\n              " : ""};

        // Move the plane towards the camera by a margin dependent on the line width (approximated in world space). This tolerance corrects for the
        // non-planarity in most cases, but sharp joins can place the prev vertices at arbitrary positions so markers can still clip.
        float offset = lineWidth * perScreenPixelRatio;
        planeOrigin *= (1.0 - offset);

        // Intersect camera ray with the plane and make sure it is within clip space
        vec3 rayDir = normalize(displacedPos);
        vec3 intersection;
        if (rayIntersectPlane(rayDir, planeOrigin, planeNormal, intersection) && intersection.z < -nearFar[0] && intersection.z > -nearFar[1]) {
          return vec4(intersection.xyz, 1.0);
        }

        // Fallback: use depth of pos or prev, whichever is closer to the camera
        float minDepth = planeOrigin.z > prev.z ? length(planeOrigin) : length(prev);
        displacedPos *= minDepth / length(displacedPos);
        return vec4(displacedPos.xyz, 1.0);
      }
  `)), S.uniforms.add(new o2("pixelRatio", (e7, r2) => r2.camera.pixelRatio)), S.code.add(n`
    void main(void) {
      float coverage = 1.0;

      // Check for special value of uv0.y which is used by the Renderer when graphics
      // are removed before the VBO is recompacted. If this is the case, then we just
      // project outside of clip space.
      if (uv0.y == 0.0) {
        // Project out of clip space
        gl_Position = vec4(1e038, 1e038, 1e038, 1.0);
      }
      else {
        float lineSize = getSize();
        float lineWidth = max(lineSize, 1.0) * pixelRatio;

        vec4 pos  = view * vec4(position.xyz, 1.0);
        vec4 prev = view * vec4(auxpos1.xyz, 1.0);
        clip(pos, prev);

        vec4 posScreen = projectAndScale(pos);
        vec4 prevScreen = projectAndScale(prev);

        vec2 segment = posScreen.xy - prevScreen.xy;

        // normalize vector along line segment
        float segmentLen = length(segment);
        segment = (segmentLen > 0.001) ? segment / segmentLen : vec2(0.0, 0.0);

        // displace according to position in the texture
        vec2 displacementDirU = PERPENDICULAR(segment);
        vec2 displacementDirV = segment;

        float displacementLen = ${n.float(n3 / i2)} * lineWidth;

        vec4 displacedPosScreen = posScreen;
        displacedPosScreen.xy += uv0.x * displacementDirU * displacementLen + uv0.y * displacementDirV * displacementLen;
  `), b2.draped || S.code.add(n`vec3 posRight = inverseProject(posScreen + vec4(displacementDirU.xy, 0.0, 0.0) * lineWidth);
vec3 posLeft = pos.xyz + (pos.xyz - posRight);
pos = toFront(displacedPosScreen, posLeft, posRight, prev.xyz, lineWidth);
displacedPosScreen = projectAndScale(pos);`), S.code.add(n`
        ${P ? "depth = pos.z;" : ""}
        linearDepth = (-pos.z - nearFar[0]) / (nearFar[1] - nearFar[0]);

        // Convert back into NDC
        displacedPosScreen.xy = (displacedPosScreen.xy / viewport.zw) * displacedPosScreen.w;

        // Convert texture coordinate into [0,1] and cancel out perspective correct interpolation
        vUV = (uv0 + 1.0) / 2.0;
        vUV *= displacedPosScreen.w;

        vSize = displacementLen;

        vColor = getColor();
        vColor.a *= coverage;

        // Use camera space for slicing
        vpos = pos.xyz;

        gl_Position = displacedPosScreen;
      }
    }
  `), P && x2.include(n2, b2), x2.include(u, b2), j.uniforms.add([new e3("intrinsicColor", (e7) => e7.color), new c("tex", (e7) => e7.texture)]), j.include(e5), j.code.add(n`
  void main() {
    discardBySlice(vpos);
    ${P ? "terrainDepthTest(gl_FragCoord, depth);" : ""}

    vec4 finalColor = intrinsicColor * vColor;

    // Offset texture coordinate s.t. we sample texel centers
    float texelSize = ${n.float(1 / n3)};
    vec2 samplePos = vUV * gl_FragCoord.w + vec2(0.5, -0.5) * texelSize;

    // Evaluate sdf
    float sdf = rgba2float(texture2D(tex, samplePos)) - 0.5;
    float distance = sdf * vSize;

    // Grow by a halfpixel to make sure the line is fully covered by the cross marker
    // (otherwise there will be a halo if they are different colours)
    distance -= 0.5;

    finalColor.a *= clamp(0.5 - distance, 0.0, 1.0);

    if (finalColor.a < ${n.float(t)}) {
      discard;
    }

    ${b2.output === o.Alpha ? n`gl_FragColor = vec4(finalColor.a);` : ""}
    ${b2.output === o.Color ? n`gl_FragColor = highlightSlice(finalColor, vpos);` : ""}
    ${b2.output === o.Color && b2.transparencyPassType === O2.Color ? "gl_FragColor = premultiplyAlpha(gl_FragColor);" : ""}
    ${b2.output === o.Highlight ? n`gl_FragColor = vec4(1.0);` : ""}
    ${b2.output === o.Depth ? n`outputDepth(linearDepth);` : ""}
  }
  `), x2;
}
var x = Object.freeze(Object.defineProperty({ __proto__: null, build: b }, Symbol.toStringTag, { value: "Module" }));

export {
  e6 as e,
  b,
  x
};
//# sourceMappingURL=chunk-PGSJOMCO.js.map
