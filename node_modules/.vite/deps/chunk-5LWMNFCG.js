import {
  u as u3
} from "./chunk-PWYPPSAW.js";
import {
  t as t2
} from "./chunk-QXYW5CVF.js";
import {
  D as D2
} from "./chunk-Z7AZMEL6.js";
import {
  _,
  n as n4
} from "./chunk-T3KDRLPE.js";
import {
  n as n3,
  u as u2
} from "./chunk-EJ7RFMRW.js";
import {
  D,
  E,
  G,
  L,
  M,
  P,
  V as V2,
  Y,
  u
} from "./chunk-FPMD6IB4.js";
import {
  e as e3,
  r as r2
} from "./chunk-EEJIELE6.js";
import {
  l
} from "./chunk-MDCKEJ7B.js";
import {
  e as e2
} from "./chunk-NAIF4GWX.js";
import {
  a as a4
} from "./chunk-KVF4M6PZ.js";
import {
  n as n2
} from "./chunk-P6G64ARX.js";
import {
  n
} from "./chunk-OIPX3EDD.js";
import {
  a as a3
} from "./chunk-65A2N4LL.js";
import {
  V,
  X
} from "./chunk-5N3FSR63.js";
import {
  a as a2,
  i
} from "./chunk-BPZGJQOB.js";
import {
  f,
  m,
  v
} from "./chunk-U3PSONS6.js";
import {
  s2
} from "./chunk-HFTNOKM2.js";
import {
  s
} from "./chunk-CVWDM4C7.js";
import {
  a2 as a,
  e2 as e,
  o2 as o,
  r,
  t
} from "./chunk-CBQWMOBK.js";

// node_modules/@arcgis/core/libs/basisu/BasisU.js
function s3() {
  if (t(i2)) {
    const t3 = (t4) => a4(`esri/libs/basisu/${t4}`);
    i2 = import("./basis_transcoder-2WRIDJII.js").then((e4) => e4.b).then(({ default: e4 }) => e4({ locateFile: t3 }).then((e5) => (e5.initializeBasis(), delete e5.then, e5)));
  }
  return i2;
}
var i2;

// node_modules/@arcgis/core/libs/basisu/TextureFormat.js
var _2;
!function(_5) {
  _5[_5.ETC1_RGB = 0] = "ETC1_RGB", _5[_5.ETC2_RGBA = 1] = "ETC2_RGBA", _5[_5.BC1_RGB = 2] = "BC1_RGB", _5[_5.BC3_RGBA = 3] = "BC3_RGBA", _5[_5.BC4_R = 4] = "BC4_R", _5[_5.BC5_RG = 5] = "BC5_RG", _5[_5.BC7_M6_RGB = 6] = "BC7_M6_RGB", _5[_5.BC7_M5_RGBA = 7] = "BC7_M5_RGBA", _5[_5.PVRTC1_4_RGB = 8] = "PVRTC1_4_RGB", _5[_5.PVRTC1_4_RGBA = 9] = "PVRTC1_4_RGBA", _5[_5.ASTC_4x4_RGBA = 10] = "ASTC_4x4_RGBA", _5[_5.ATC_RGB = 11] = "ATC_RGB", _5[_5.ATC_RGBA = 12] = "ATC_RGBA", _5[_5.FXT1_RGB = 17] = "FXT1_RGB", _5[_5.PVRTC2_4_RGB = 18] = "PVRTC2_4_RGB", _5[_5.PVRTC2_4_RGBA = 19] = "PVRTC2_4_RGBA", _5[_5.ETC2_EAC_R11 = 20] = "ETC2_EAC_R11", _5[_5.ETC2_EAC_RG11 = 21] = "ETC2_EAC_RG11", _5[_5.RGBA32 = 13] = "RGBA32", _5[_5.RGB565 = 14] = "RGB565", _5[_5.BGR565 = 15] = "BGR565", _5[_5.RGBA4444 = 16] = "RGBA4444";
}(_2 || (_2 = {}));

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/BasisUtil.js
var g = null;
var l2 = null;
async function c() {
  return t(l2) && (l2 = s3(), g = await l2), l2;
}
function u4(t3, n5) {
  if (t(g))
    return t3.byteLength;
  const r3 = new g.BasisFile(new Uint8Array(t3)), s5 = T(r3) ? E2(r3.getNumLevels(0), r3.getHasAlpha(), r3.getImageWidth(0, 0), r3.getImageHeight(0, 0), n5) : 0;
  return r3.close(), r3.delete(), s5;
}
function m2(t3, n5) {
  if (t(g))
    return t3.byteLength;
  const r3 = new g.KTX2File(new Uint8Array(t3)), s5 = _3(r3) ? E2(r3.getLevels(), r3.getHasAlpha(), r3.getWidth(), r3.getHeight(), n5) : 0;
  return r3.close(), r3.delete(), s5;
}
function E2(e4, t3, n5, s5, i4) {
  const a6 = _(t3 ? u.COMPRESSED_RGBA8_ETC2_EAC : u.COMPRESSED_RGB8_ETC2), g3 = i4 && e4 > 1 ? (4 ** e4 - 1) / (3 * 4 ** (e4 - 1)) : 1;
  return Math.ceil(n5 * s5 * a6 * g3);
}
function T(e4) {
  return e4.getNumImages() >= 1 && !e4.isUASTC();
}
function _3(e4) {
  return e4.getFaces() >= 1 && e4.isETC1S();
}
async function h(t3, n5, r3) {
  t(g) && (g = await c());
  const s5 = new g.BasisFile(new Uint8Array(r3));
  if (!T(s5))
    return null;
  s5.startTranscoding();
  const i4 = p(t3, n5, s5.getNumLevels(0), s5.getHasAlpha(), s5.getImageWidth(0, 0), s5.getImageHeight(0, 0), (e4, t4) => s5.getImageTranscodedSizeInBytes(0, e4, t4), (e4, t4, n6) => s5.transcodeImage(n6, 0, e4, t4, 0, 0));
  return s5.close(), s5.delete(), i4;
}
async function A(t3, n5, r3) {
  t(g) && (g = await c());
  const s5 = new g.KTX2File(new Uint8Array(r3));
  if (!_3(s5))
    return null;
  s5.startTranscoding();
  const i4 = p(t3, n5, s5.getLevels(), s5.getHasAlpha(), s5.getWidth(), s5.getHeight(), (e4, t4) => s5.getImageTranscodedSizeInBytes(e4, 0, 0, t4), (e4, t4, n6) => s5.transcodeImage(n6, e4, 0, 0, t4, 0, -1, -1));
  return s5.close(), s5.delete(), i4;
}
function p(e4, t3, o2, g3, l4, c3, u6, m4) {
  const { compressedTextureETC: E4, compressedTextureS3TC: T3 } = e4.capabilities, [_5, h3] = E4 ? g3 ? [_2.ETC2_RGBA, u.COMPRESSED_RGBA8_ETC2_EAC] : [_2.ETC1_RGB, u.COMPRESSED_RGB8_ETC2] : T3 ? g3 ? [_2.BC3_RGBA, u.COMPRESSED_RGBA_S3TC_DXT5_EXT] : [_2.BC1_RGB, u.COMPRESSED_RGB_S3TC_DXT1_EXT] : [_2.RGBA32, P.RGBA], A3 = t3.hasMipmap ? o2 : Math.min(1, o2), p3 = [];
  for (let n5 = 0; n5 < A3; n5++)
    p3.push(new Uint8Array(u6(n5, _5))), m4(n5, _5, p3[n5]);
  const C2 = p3.length > 1, d2 = C2 ? L.LINEAR_MIPMAP_LINEAR : L.LINEAR, R = { ...t3, samplingMode: d2, hasMipmap: C2, internalFormat: h3, width: l4, height: c3 };
  return new u2(e4, R, { type: "compressed", levels: p3 });
}

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/DDSUtil.js
var a5 = s.getLogger("esri.views.3d.webgl-engine.lib.DDSUtil");
var i3 = 542327876;
var s4 = 131072;
var l3 = 4;
function u5(e4) {
  return e4.charCodeAt(0) + (e4.charCodeAt(1) << 8) + (e4.charCodeAt(2) << 16) + (e4.charCodeAt(3) << 24);
}
function m3(e4) {
  return String.fromCharCode(255 & e4, e4 >> 8 & 255, e4 >> 16 & 255, e4 >> 24 & 255);
}
var c2 = u5("DXT1");
var h2 = u5("DXT3");
var p2 = u5("DXT5");
var d = 31;
var g2 = 0;
var f2 = 1;
var C = 2;
var w = 3;
var D3 = 4;
var _4 = 7;
var T2 = 20;
var A2 = 21;
function E3(e4, t3, n5) {
  const { textureData: a6, internalFormat: i4, width: s5, height: l4 } = S(n5, t3.hasMipmap);
  return t3.samplingMode = a6.levels.length > 1 ? L.LINEAR_MIPMAP_LINEAR : L.LINEAR, t3.hasMipmap = a6.levels.length > 1, t3.internalFormat = i4, t3.width = s5, t3.height = l4, new u2(e4, t3, a6);
}
function S(e4, r3) {
  const o2 = new Int32Array(e4, 0, d);
  if (o2[g2] !== i3)
    return a5.error("Invalid magic number in DDS header"), null;
  if (!(o2[T2] & l3))
    return a5.error("Unsupported format, must contain a FourCC code"), null;
  const u6 = o2[A2];
  let E4, S2;
  switch (u6) {
    case c2:
      E4 = 8, S2 = u.COMPRESSED_RGB_S3TC_DXT1_EXT;
      break;
    case h2:
      E4 = 16, S2 = u.COMPRESSED_RGBA_S3TC_DXT3_EXT;
      break;
    case p2:
      E4 = 16, S2 = u.COMPRESSED_RGBA_S3TC_DXT5_EXT;
      break;
    default:
      return a5.error("Unsupported FourCC code:", m3(u6)), null;
  }
  let M2 = 1, R = o2[D3], x = o2[w];
  0 == (3 & R) && 0 == (3 & x) || (a5.warn("Rounding up compressed texture size to nearest multiple of 4."), R = R + 3 & -4, x = x + 3 & -4);
  const X2 = R, b = x;
  let I, v2;
  o2[C] & s4 && false !== r3 && (M2 = Math.max(1, o2[_4])), 1 === M2 || i(R) && i(x) || (a5.warn("Ignoring mipmaps of non power of two sized compressed texture."), M2 = 1);
  let F = o2[f2] + 4;
  const L3 = [];
  for (let t3 = 0; t3 < M2; ++t3)
    v2 = (R + 3 >> 2) * (x + 3 >> 2) * E4, I = new Uint8Array(e4, F, v2), L3.push(I), F += v2, R = Math.max(1, R >> 1), x = Math.max(1, x >> 1);
  return { textureData: { type: "compressed", levels: L3 }, internalFormat: S2, width: X2, height: b };
}

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/Texture.js
var L2 = class extends r2 {
  constructor(t3, e4) {
    super(), this.data = t3, this.type = e3.Texture, this._glTexture = null, this._powerOfTwoStretchInfo = null, this._loadingPromise = null, this._loadingController = null, this.events = new n(), this.params = e4 || {}, this.params.mipmap = false !== this.params.mipmap, this.params.noUnpackFlip = this.params.noUnpackFlip || false, this.params.preMultiplyAlpha = this.params.preMultiplyAlpha || false, this.params.wrap = this.params.wrap || { s: D.REPEAT, t: D.REPEAT }, this.params.powerOfTwoResizeMode = this.params.powerOfTwoResizeMode || l.STRETCH, this.estimatedTexMemRequired = L2._estimateTexMemRequired(this.data, this.params), this._startPreload();
  }
  _startPreload() {
    const t3 = this.data;
    t(t3) || (t3 instanceof HTMLVideoElement ? this._startPreloadVideoElement(t3) : t3 instanceof HTMLImageElement && this._startPreloadImageElement(t3));
  }
  _startPreloadVideoElement(t3) {
    if (!(V(t3.src) || "auto" === t3.preload && t3.crossOrigin)) {
      t3.preload = "auto", t3.crossOrigin = "anonymous";
      const e4 = !t3.paused;
      if (t3.src = t3.src, e4 && t3.autoplay) {
        const e5 = () => {
          t3.removeEventListener("canplay", e5), t3.play();
        };
        t3.addEventListener("canplay", e5);
      }
    }
  }
  _startPreloadImageElement(t3) {
    X(t3.src) || V(t3.src) || t3.crossOrigin || (t3.crossOrigin = "anonymous", t3.src = t3.src);
  }
  static _getDataDimensions(t3) {
    return t3 instanceof HTMLVideoElement ? { width: t3.videoWidth, height: t3.videoHeight } : t3;
  }
  static _estimateTexMemRequired(t3, e4) {
    if (t(t3))
      return 0;
    if (o(t3) || e(t3))
      return e4.encoding === L2.KTX2_ENCODING ? m2(t3, e4.mipmap) : e4.encoding === L2.BASIS_ENCODING ? u4(t3, e4.mipmap) : t3.byteLength;
    const { width: r3, height: i4 } = t3 instanceof Image || t3 instanceof ImageData || t3 instanceof HTMLCanvasElement || t3 instanceof HTMLVideoElement ? L2._getDataDimensions(t3) : e4;
    return (e4.mipmap ? 4 / 3 : 1) * r3 * i4 * (e4.components || 4) || 0;
  }
  dispose() {
    this.data = void 0;
  }
  get width() {
    return this.params.width;
  }
  get height() {
    return this.params.height;
  }
  _createDescriptor(t3) {
    return { target: M.TEXTURE_2D, pixelFormat: P.RGBA, dataType: G.UNSIGNED_BYTE, wrapMode: this.params.wrap, flipped: !this.params.noUnpackFlip, samplingMode: this.params.mipmap ? L.LINEAR_MIPMAP_LINEAR : L.LINEAR, hasMipmap: this.params.mipmap, preMultiplyAlpha: this.params.preMultiplyAlpha, maxAnisotropy: this.params.maxAnisotropy ?? (this.params.mipmap ? t3.parameters.maxMaxAnisotropy : 1) };
  }
  get glTexture() {
    return this._glTexture;
  }
  load(t3, e4) {
    if (r(this._glTexture))
      return this._glTexture;
    if (r(this._loadingPromise))
      return this._loadingPromise;
    const r3 = this.data;
    return t(r3) ? (this._glTexture = new u2(t3, this._createDescriptor(t3), null), this._glTexture) : "string" == typeof r3 ? this._loadFromURL(t3, e4, r3) : r3 instanceof Image ? this._loadFromImageElement(t3, e4, r3) : r3 instanceof HTMLVideoElement ? this._loadFromVideoElement(t3, e4, r3) : r3 instanceof ImageData || r3 instanceof HTMLCanvasElement ? this._loadFromImage(t3, r3, e4) : (o(r3) || e(r3)) && this.params.encoding === L2.DDS_ENCODING ? (this.data = void 0, this._loadFromDDSData(t3, r3)) : (o(r3) || e(r3)) && this.params.encoding === L2.KTX2_ENCODING ? (this.data = void 0, this._loadFromKTX2(t3, r3)) : (o(r3) || e(r3)) && this.params.encoding === L2.BASIS_ENCODING ? (this.data = void 0, this._loadFromBasis(t3, r3)) : e(r3) ? this._loadFromPixelData(t3, r3) : o(r3) ? this._loadFromPixelData(t3, new Uint8Array(r3)) : null;
  }
  get requiresFrameUpdates() {
    return this.data instanceof HTMLVideoElement;
  }
  frameUpdate(t3, e4, r3) {
    if (!(this.data instanceof HTMLVideoElement) || t(this._glTexture))
      return r3;
    if (this.data.readyState < j.HAVE_CURRENT_DATA || r3 === this.data.currentTime)
      return r3;
    if (r(this._powerOfTwoStretchInfo)) {
      const { framebuffer: r4, vao: i4, sourceTexture: s5 } = this._powerOfTwoStretchInfo;
      s5.setData(this.data), this._drawStretchedTexture(t3, e4, r4, i4, s5, this._glTexture);
    } else {
      const { videoWidth: t4, videoHeight: e5 } = this.data, { width: r4, height: i4 } = this._glTexture.descriptor;
      t4 !== r4 || e5 !== i4 ? this._glTexture.updateData(0, 0, 0, Math.min(t4, r4), Math.min(e5, i4), this.data) : this._glTexture.setData(this.data);
    }
    return this._glTexture.descriptor.hasMipmap && this._glTexture.generateMipmap(), this.params.updateCallback && this.params.updateCallback(), this.data.currentTime;
  }
  _loadFromDDSData(t3, e4) {
    return this._glTexture = E3(t3, this._createDescriptor(t3), e4), this._glTexture;
  }
  _loadFromKTX2(t3, e4) {
    return this._loadAsync(() => A(t3, this._createDescriptor(t3), e4).then((t4) => (this._glTexture = t4, t4)));
  }
  _loadFromBasis(t3, e4) {
    return this._loadAsync(() => h(t3, this._createDescriptor(t3), e4).then((t4) => (this._glTexture = t4, t4)));
  }
  _loadFromPixelData(t3, e4) {
    e2(this.params.width > 0 && this.params.height > 0);
    const r3 = this._createDescriptor(t3);
    return r3.pixelFormat = 1 === this.params.components ? P.LUMINANCE : 3 === this.params.components ? P.RGB : P.RGBA, r3.width = this.params.width, r3.height = this.params.height, this._glTexture = new u2(t3, r3, e4), this._glTexture;
  }
  _loadFromURL(t3, e4, r3) {
    return this._loadAsync(async (i4) => {
      const s5 = await t2(r3, { signal: i4 });
      return f(i4), this._loadFromImage(t3, s5, e4);
    });
  }
  _loadFromImageElement(t3, e4, r3) {
    return r3.complete ? this._loadFromImage(t3, r3, e4) : this._loadAsync(async (i4) => {
      const s5 = await a3(r3, r3.src, false, i4);
      return f(i4), this._loadFromImage(t3, s5, e4);
    });
  }
  _loadFromVideoElement(t3, e4, r3) {
    return r3.readyState >= j.HAVE_CURRENT_DATA ? this._loadFromImage(t3, r3, e4) : this._loadFromVideoElementAsync(t3, e4, r3);
  }
  _loadFromVideoElementAsync(t3, r3, i4) {
    return this._loadAsync((s5) => new Promise((a6, o2) => {
      const m4 = () => {
        i4.removeEventListener("loadeddata", p3), i4.removeEventListener("error", d2), a(_5);
      }, p3 = () => {
        i4.readyState >= j.HAVE_CURRENT_DATA && (m4(), a6(this._loadFromImage(t3, i4, r3)));
      }, d2 = (t4) => {
        m4(), o2(t4 || new s2("Failed to load video"));
      };
      i4.addEventListener("loadeddata", p3), i4.addEventListener("error", d2);
      const _5 = v(s5, () => d2(m()));
    }));
  }
  _loadFromImage(t3, e4, r3) {
    const s5 = L2._getDataDimensions(e4);
    this.params.width = s5.width, this.params.height = s5.height;
    const a6 = this._createDescriptor(t3);
    return a6.pixelFormat = 3 === this.params.components ? P.RGB : P.RGBA, !this._requiresPowerOfTwo(t3, a6) || i(s5.width) && i(s5.height) ? (a6.width = s5.width, a6.height = s5.height, this._glTexture = new u2(t3, a6, e4), this._glTexture) : (this._glTexture = this._makePowerOfTwoTexture(t3, e4, s5, a6, r3), this._glTexture);
  }
  _loadAsync(t3) {
    const e4 = new AbortController();
    this._loadingController = e4;
    const r3 = t3(e4.signal);
    this._loadingPromise = r3;
    const i4 = () => {
      this._loadingController === e4 && (this._loadingController = null), this._loadingPromise === r3 && (this._loadingPromise = null);
    };
    return r3.then(i4, i4), r3;
  }
  _requiresPowerOfTwo(t3, e4) {
    const r3 = D.CLAMP_TO_EDGE, i4 = "number" == typeof e4.wrapMode ? e4.wrapMode === r3 : e4.wrapMode.s === r3 && e4.wrapMode.t === r3;
    return !n3(t3.gl) && (e4.hasMipmap || !i4);
  }
  _makePowerOfTwoTexture(e4, r3, i4, a6, o2) {
    const { width: n5, height: m4 } = i4, h3 = a2(n5), l4 = a2(m4);
    let p3;
    switch (a6.width = h3, a6.height = l4, this.params.powerOfTwoResizeMode) {
      case l.PAD:
        a6.textureCoordinateScaleFactor = [n5 / h3, m4 / l4], p3 = new u2(e4, a6), p3.updateData(0, 0, 0, n5, m4, r3);
        break;
      case l.STRETCH:
      case null:
      case void 0:
        p3 = this._stretchToPowerOfTwo(e4, r3, a6, o2());
        break;
      default:
        n2(this.params.powerOfTwoResizeMode);
    }
    return a6.hasMipmap && p3.generateMipmap(), p3;
  }
  _stretchToPowerOfTwo(t3, e4, r3, i4) {
    const s5 = new u2(t3, r3), a6 = new D2(t3, { colorTarget: Y.TEXTURE, depthStencilTarget: V2.NONE }, s5), o2 = new u2(t3, { target: M.TEXTURE_2D, pixelFormat: r3.pixelFormat, dataType: G.UNSIGNED_BYTE, wrapMode: D.CLAMP_TO_EDGE, samplingMode: L.LINEAR, flipped: !!r3.flipped, maxAnisotropy: 8, preMultiplyAlpha: r3.preMultiplyAlpha }, e4), n5 = u3(t3), m4 = t3.getBoundFramebufferObject();
    return this._drawStretchedTexture(t3, i4, a6, n5, o2, s5), this.requiresFrameUpdates ? this._powerOfTwoStretchInfo = { vao: n5, sourceTexture: o2, framebuffer: a6 } : (n5.dispose(true), o2.dispose(), a6.detachColorTexture(), a6.dispose()), t3.bindFramebuffer(m4), s5;
  }
  _drawStretchedTexture(t3, e4, r3, i4, s5, a6) {
    t3.bindFramebuffer(r3);
    const o2 = t3.getViewport();
    t3.setViewport(0, 0, a6.descriptor.width, a6.descriptor.height);
    const n5 = t3.bindTechnique(e4);
    n5.setUniform4f("uColor", 1, 1, 1, 1), n5.bindTexture("tex", s5), t3.bindVAO(i4), t3.drawArrays(E.TRIANGLE_STRIP, 0, n4(i4, "geometry")), t3.bindFramebuffer(null), t3.setViewport(o2.x, o2.y, o2.width, o2.height);
  }
  unload() {
    if (r(this._powerOfTwoStretchInfo)) {
      const { framebuffer: t3, vao: e4, sourceTexture: r3 } = this._powerOfTwoStretchInfo;
      e4.dispose(true), r3.dispose(), t3.dispose(), this._glTexture = null, this._powerOfTwoStretchInfo = null;
    }
    if (r(this._glTexture) && (this._glTexture.dispose(), this._glTexture = null), r(this._loadingController)) {
      const t3 = this._loadingController;
      this._loadingController = null, this._loadingPromise = null, t3.abort();
    }
    this.events.emit("unloaded");
  }
};
var j;
L2.DDS_ENCODING = "image/vnd-ms.dds", L2.KTX2_ENCODING = "image/ktx2", L2.BASIS_ENCODING = "image/x.basis", function(t3) {
  t3[t3.HAVE_NOTHING = 0] = "HAVE_NOTHING", t3[t3.HAVE_METADATA = 1] = "HAVE_METADATA", t3[t3.HAVE_CURRENT_DATA = 2] = "HAVE_CURRENT_DATA", t3[t3.HAVE_FUTURE_DATA = 3] = "HAVE_FUTURE_DATA", t3[t3.HAVE_ENOUGH_DATA = 4] = "HAVE_ENOUGH_DATA";
}(j || (j = {}));

export {
  c,
  L2 as L
};
//# sourceMappingURL=chunk-5LWMNFCG.js.map
